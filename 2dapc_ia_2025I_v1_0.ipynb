{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "4WFjVPQ3C-sY"
      },
      "source": [
        "# Machine Learning. Caso: Reconocimiento de Dígitos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instrucciones:\n",
        "* Por favor, complete las tareas de este notebook. Deberá enviar este notebook, así como una versión en PDF, a la plataforma Univirtual.\n",
        "* Para crear el PDF, vaya a Archivo > Descargar como. Puede exportar a PDF mediante Latex, o exportar a HTML y luego imprimir a PDF.\n",
        "* Añada una explicación clara de su enfoque y una interpretación detallada de sus resultados para cada subpregunta. Para ello, utilice celdas Markdown.\n",
        "\n",
        "* Añada a continuación los nombres de todos los miembros del equipo."
      ],
      "metadata": {
        "id": "O33QiLjzu3tv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xALIs1G-C-sb"
      },
      "source": [
        "**Integrantes:**\n",
        "\n",
        "1.   Integrante 1:\n",
        "2.   Integrante 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xIafElEC-sb"
      },
      "source": [
        "## MNIST\n",
        "\n",
        "Se va a usar para esta práctica la base de datos [MNIST](https://www.openml.org/d/554)  de dígitos manuscritos que cuenta con  784 características (datos brutos disponibles en: http://yann.lecun.com/exdb/mnist/9). Esta base de datos contiene 70.000 imágenes de dígitos escritos a mano, clasificados en 10 tipos de dígitos (del 0 al 9), cada uno representado por valores de 28 por 28 píxeles. Puede descargarlo de OpenML y visualizar algunos de los ejemplos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install preamble"
      ],
      "metadata": {
        "id": "_cwrhC65DUS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openml"
      ],
      "metadata": {
        "id": "ZbHF-A0YGJ3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k9UErhVC-sb"
      },
      "outputs": [],
      "source": [
        "# Imports generales\n",
        "%matplotlib inline\n",
        "from preamble import *\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['savefig.dpi'] = 100 # Esto controla el tamanio de tus imagenes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openml as oml"
      ],
      "metadata": {
        "id": "DkI3n6UZGUr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq4wBXmSC-sc"
      },
      "outputs": [],
      "source": [
        "# Descarga de la data de MINST. Demora un poco la primera vez\n",
        "mnist = oml.datasets.get_dataset(554)\n",
        "X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute);\n",
        "mnist_classes = {0:\"Cero\", 1: \"Uno\", 2: \"Dos\", 3: \"Tres\", 4: \"Cuatro\", 5: \"Cinco\",\n",
        "                  6: \"Seis\", 7: \"Siete\", 8: \"Ocho\", 9: \"Nueve\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "vpzY_MU9PjyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOEL6eM_C-sc"
      },
      "outputs": [],
      "source": [
        "# Toma algunos ejemplos aleatorios, reescala las images al tamaño de 32x32 image y muestralas\n",
        "from random import randint\n",
        "fig, axes = plt.subplots(1, 5,  figsize=(10, 5))\n",
        "for i in range(5):\n",
        "    n = randint(0,70000)\n",
        "    axes[i].imshow(X.values[n].reshape(28, 28), cmap=plt.cm.gray_r)\n",
        "    axes[i].set_xlabel((mnist_classes[int(y.values[n])]))\n",
        "    axes[i].set_xticks(()), axes[i].set_yticks(())\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1_ Evalúe k-Nearest Neighbors, Regresión Logística y SVM Lineal. (2.5 puntos)\n",
        "- Tome unav*submuestra estratificada* del 10% de los datos. Use esta muestra para todos los pasos siguientes.\n",
        "- Evalúe los 3 clasificadores con sus configuraciones por defecto. Use cross-validation con 3 folds, muestre el accuracy y la desviación estándar.\n",
        "- Discuta cuál funciona mejor.\n",
        "\n",
        "Nota: puede utilizar una muestra más pequeña durante las pruebas y la corrección de errores."
      ],
      "metadata": {
        "id": "NtvaWl74yzFG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGwodBCIC-sc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2_ Ajuste los parámetros usando GridSearchCV. (2.5 puntos)\n",
        "- Varíe el hiperparámetro principal (C o k) para los 3 modelos. ¿Mejoran los resultados?  ¿Qué rangos influyen en el rendimiento?\n",
        "- Visualice el score de prueba y el score de entrenamiento en función de los parámetros de los tres modelos. Discuta cuándo (para qué valores) del modelo se produce underfitting u overfitting.\n",
        "\n",
        "Nota: Puede utilizar un line plot o 1D heatmap  para la visualización. Utilice de nuevo la validación cruzada (3-fold cross-validation) y el accuracy."
      ],
      "metadata": {
        "id": "c4iOjO3Xz_b0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JLgQ7N9C-sd"
      },
      "outputs": [],
      "source": [
        "# Puede utilizar este gráfico genérico para  la búsqueda en 1D (1D grid search)\n",
        "# grid_search: el resultado del GridSearchCV\n",
        "# param_name: el nombre del parámetro que se está variando\n",
        "def plot_tuning(grid_search, param_name):\n",
        "    plt.figure()\n",
        "    plt.plot(grid_search.param_grid[param_name], grid_search.cv_results_['mean_test_score'], marker = '.', label = 'Test score')\n",
        "    plt.plot(grid_search.param_grid[param_name], grid_search.cv_results_['mean_train_score'], marker = '.', label = 'Train score')\n",
        "    ax = plt.gca()\n",
        "    ax.set_ylabel('score (ACC)')\n",
        "    ax.set_xlabel(param_name)\n",
        "    ax.legend()\n",
        "    plt.title(grid_search.best_estimator_.__class__.__name__)\n",
        "    print('Best configuration:' + str(grid_search.best_params_))\n",
        "    print('Best score (ACC):' + str(grid_search.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3_ Analice qué tipos de clasificaciones erróneas (misclassifications) se cometen (2.5 puntos)\n",
        "- Cree una división estándar train_test\n",
        "- Entrene la Regresión Logística en los datos de entrenamiento y genere predicciones en el conjunto de prueba\n",
        "- Visualice (como arriba) unos cuantos ejemplos mal clasificados por Regresión Logística. Discusión: ¿son realmente casos difíciles?\n",
        "- Construya la matriz de confusión ('confusion_matrix') de todas las predicciones. Discuta en qué clases comunmente se produce confusión/errores."
      ],
      "metadata": {
        "id": "RAjl_E3o10Iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4_ Visualice los parámetros del modelo (2 puntos)\n",
        "- Recupere todos los parámetros del modelo (coefficients) para la Regresión Logística y Linear Support Vector Machines\n",
        "- Plot los coeficientes en una imagen de 28*28 como en el caso anterior.\n",
        "- Interprete los resultados. ¿A qué píxeles prestan más atención los modelos? ¿Por qué? ¿Hay alguna diferencia entre ambos modelos?"
      ],
      "metadata": {
        "id": "Ydt_lAb622dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5_ Ahora use el dataset CIFAR-10  (Alex Krizhevsky (2009) Learning Multiple Layers of Features from Tiny Images, Tech Report.).  (2.5 puntos)\n",
        "\n",
        " [CIFAR-10](https://www.openml.org/d/40927)  es un subconjunto etiquetado del conjunto de datos de 80 millones de imágenes diminutas. Consta (originalmente) de 32x32 imágenes en color que representan 10 clases de objetos:\n",
        "\n",
        "0.   avión\n",
        "1.   automóvil\n",
        "2.   pájaro\n",
        "3.   gato\n",
        "4.   ciervo\n",
        "5.   perro\n",
        "6.   rana\n",
        "7.   caballo\n",
        "8.   barco\n",
        "9.   camión\n",
        "\n",
        "CIFAR-10 contiene 6000 imágenes por clase. La división original de entrenamiento-prueba las dividió aleatoriamente en 5000 imágenes de entrenamiento y 1000 de prueba por clase.\n",
        "\n",
        "\n",
        "*   ¿Cómo aplicarías en este dataset los procesos previoes al paso 1 de este notebook (es decir, la lectura, el pre-tratamiento y el plot), ¿qué ajustes  deberías hacer a las imágenes?. Justifique su respuesta.\n",
        "\n",
        "*   ¿Cómo aplicarías los pasos del punto 1 de este notebook (es decir Evalúe k-Nearest Neighbors, Regresión Logística y SVM Lineal). Muestre sus resultados, coméntelos y explique las adecuaciones que ha tenido que realizar.\n",
        "\n",
        "*   Puede usar como base el código que se presenta en las líneas siguientes:\n",
        "\n"
      ],
      "metadata": {
        "id": "DPFuLnE8WLBL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUGuNXoXW1RL"
      },
      "outputs": [],
      "source": [
        "# Descargar la data para el dataset CIFAR-10. Demora un poco la primera vez\n",
        "cifar = oml.datasets.get_dataset(40927)\n",
        "X_ori, y_ori, _, _ = cifar.get_data(target=cifar.default_target_attribute);\n",
        "cifar_classes = {0:\"airplane\", 1: \"automobile\", 2: \"bird\", 3: \"cat\", 4: \"deer\", 5: \"dog\",\n",
        "                  6: \"frog\", 7: \"horse\", 8: \"ship\", 9: \"truck\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tUGEbZv_Wkgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ori"
      ],
      "metadata": {
        "id": "SGyrf_p78eZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajuste el código de las líneas siguientes para que funcione de manera correcta para pintar las imágenes en escala de grises (grayscale).  Cambie lo que considere necesario."
      ],
      "metadata": {
        "id": "mcigDehe8uaA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9V6js16XD6V"
      },
      "outputs": [],
      "source": [
        "# Toma algunos ejemplos aleatorios, reescala las images al tamaño de 32x32 image y muestralas\n",
        "from random import randint\n",
        "fig, axes = plt.subplots(1, 5,  figsize=(10, 5))\n",
        "for i in range(5):\n",
        "    n = randint(0,60000)\n",
        "    axes[i].imshow(X_ori.values[n].reshape(32, 32), cmap=plt.cm.gray_r)\n",
        "    axes[i].set_xlabel((cifar_classes[int(y_ori.values[n])]))\n",
        "    axes[i].set_xticks(()), axes[i].set_yticks(())\n",
        "plt.show();"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}